{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline.   This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "**Scoring:** Out of $10$ points\n",
    "\n",
    "- Each Developing => $-1$ pts\n",
    "- Each Unsatisfactory/Missing => $-2$ pts\n",
    "\t- until the score is 0\n",
    "\n",
    "If students address the detailed feedback in a future checkpoint, they will **earn these points back**.\n",
    "\n",
    "\n",
    "|                   | Unsatisfactory                                                                                                                                                                                                                                                                                    | Developing                                                                                                                                                                                                                                                                                                                                   | Proficient                                                                                                                                                                                                                                                    | Excellent                                                                                                                                                                                                                                                                                                                      |\n",
    "|-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Research question | The research issue remains unclear. The research purpose, questions, hypotheses, definitions variables, and controls are still largely undefined, or when they are poorly formed, ambiguous, or not logically connected to the description of the problem. Unclear connections to the literature. | The research issue is identified, but the statement is too broad or fails to establish the importance of the problem. The research purpose, questions, hypotheses, definitions or variables, and controls are poorly formed, ambiguous, or not logically connected to the description of the problem. Unclear connections to the literature. | Identifies a relevant research issue. Research questions are succinctly stated, connected to the research issue, and supported by the literature. Variables and controls have been identified and described. Connections are established with the literature. | Presents a significant research problem. Articulates clear, reasonable research questions given the purpose, design, and methods of the project. All variables and controls have been appropriately defined. Proposals are clearly supported by the research and theoretical literature. All elements are mutually supportive. |\n",
    "| Background        | Did not have at least 2 reliable and relevant sources. Or relevant sources were not used in relevant ways                                                                                                                                                                                         | A key component was not connected to the research literature. Selected literature was from unreliable sources. Literary supports were vague or ambiguous.                                                                                                                                                                                    | Key research components were connected to relevant, reliable theoretical and research literature.                                                                                                                                                             | The narrative integrates critical and logical details from the peer-reviewed theoretical and research literature. Each key research component is grounded in the literature. Attention is given to different perspectives, threats to validity, and opinion vs. evidence.                                                      |\n",
    "| Hypothesis        | Lacks most details; vague or interpretable in different ways. Or seems completely unrealistic.                                                                                                                                                                                                    | A key detail to understand the hypothesis or the rationale behind it was not described well enough                                                                                                                                                                                                                                           | The hypothesis is clear. All elements needed to understand the rationale were described in sufficient detail                                                                                                                                                  | The hypothesis and its rationale were described succinctly and with clarity about how they are connected to each other                                                                                                                                                                                                         |\n",
    "| Data              | Did not describe ideal dataset fully AND does not include at least one reference to an external source of data.                                                                                                                                                                         | Either does not describe the ideal dataset fully AND does not include at least one reference to an external source of data that could be used to answer the proposed question.                                                                                                                                                                                                                                                            | Ideal dataset(s) well-described and includes everything needed for answering question(s) posed. Includes at least one reference to a source of data that would be needed to fully answer the question proposed.                                                                                                                                                            | Ideal dataset(s) well-described and includes everything needed for answering question(s) posed. Includes references to all sources of data that would be needed to fully answer the question proposed. The details of the descriptions also make it clear how they support the needs of the project and discuss the differences betweeen the ideal and real datasets.                                                                                                                       |\n",
    "| Ethics            | No effort or just says we have no ethical concerns                                                                                                                                                                                                                                                | Minimal ethical section; probably just talks about data privacy and no unintended consequences discussion. Ethical concerns raised seem irrelevant.                                                                                                                                                                                          | The ethical concerns described are appropriate and sufficiently                                                                                                                                                                                               | Ethical concerns are described clearly and succinctly. This was clearly a thorough and nuanced approach to the issues                                                                                                                                                                                                          |\n",
    "| Team expectations | Lack of expectations                                                                                                                                                                                                                                                                              | The list of expectations feels incomplete and perfunctory                                                                                                                                                                                                                                                                                    | It feels like the list of expectations is complete and seems appropriate                                                                                                                                                                                      | The list clearly was the subject of a thoughtful approach and already indicates a well-working team                                                                                                                                                                                                                            |\n",
    "| Timeline          | Lack of timeline. Or timeline is completely unrealistic                                                                                                                                                                                                                                           | The timeline feels incomplete and perfunctory. The timeline feels either too fast or too slow for the progress you expect a group can make                                                                                                                                                                                                   | It feels like the timeline is complete and appropriate. it can likely be completed as is in the available amount of time                                                                                                                                      | The timeline was clearly the subject of a thoughtful approach and indicates that the team has a detailed plan that seems appropriate and completeable in the allotted time.                                                                                                                                                    |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Daniel Galicia Ortiz - Background Research\n",
    "- Jordan Chang - Data\n",
    "- Yiou Huang - Hypothesis, Background Research, Writing - Original Proposal\n",
    "- Wenxin Miao - Data\n",
    "- Johnson Chung - Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent does (the user’s attitude towards AI: another individual VS. a tool) the use of anthropomorphic versus instrumental language in app store reviews predict user satisfaction with popular AI models (including ChatGPT, Gemini, and Claude), as measured by star ratings? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is no surprise that AI has a profound impact on our lives. Before the 2010s, AI largely belonged to the realm of fiction, imagined as computers capable of humanlike conversation, reasoning and sometimes human emotion. In recent years, however, this fiction has become reality with the development of advanced models such as ChatGPT and Gemini, with roughly about 41% of Americans saying that they use these or similar tools. (Source 2) These large language models (LLMs) make AI interactions feel more human, enabling deeper integration into daily life. At the same time, a growing concern about AI has slowly grown over the last year, with topics ranging from jobs and privacy, to the decline of social interaction. (Source 1) Together, these examples highlight the wide range of human attitudes toward AI and raise an important question: can we predict how people perceive an AI tool based on how they treat and interact with it? This is a question that we feel the need to find some answer to.\n",
    "\n",
    "As noted earlier, AI is no longer a niche technology. It has become increasingly normalized in society, particularly among younger generations. For example, roughly two-thirds of teenagers in the United States report having used an AI chatbot (Source 3). This raises a natural follow-up question: how do people tend to perceive AI? The answer is somewhat surprising. It is becoming more common for individuals to develop personal or relational attitudes toward AI chatbots. One study found that 38% of users believe that large language models will eventually form “deep relationships with humans” (Source 4). Other research has also suggested a growing association between AI and emotionally meaningful human interaction. Anthropomorphism, attributing human characteristics to AI, has been shown to increase users’ willingness to adopt AI services (Source 5). Although that study emphasized the need for further testing, it still identified a positive relationship between anthropomorphism and user engagement. Together, these findings help lay the groundwork for the question we aim to investigate.\n",
    "\n",
    "Unfortunately no study is without limitations, and by examining prior research and studies we can identify weaknesses in data collection and methodology. For instance, some studies rely heavily on participants’ beliefs and self-reports, which can be influenced by popular culture and/or media narratives, limited technical understanding, and even the wording of survey questions. Framing effects—such as using terms like “erosion,” “loss,” or “control”—can shape how respondents interpret and answer questions (Source 1). Other studies face issues related to human estimation and omission. When research depends on approximations, results may overestimate or underestimate reality. Additionally, some studies do not distinguish how AI is used across contexts, such as for work, personal, or emotional purposes (Source 3). Although Source 3 draws on a nationally representative, demographically weighted sample, this does not fully address contextual gaps in AI usage. Because our focus is on measuring anthropomorphic language, no single dataset will be perfect; however, combining multiple datasets can help mitigate these limitations and produce more balanced insights.\n",
    "\n",
    "While the research and articles above analyze different aspects of the issue—such as public views of AI or patterns of AI usage—we believe there is a need for a complementary approach to determine whether a relationship between our two factors truly exists. To properly identify such a relationship, it is important to consider multiple external variables to ensure that any observed connection is meaningful rather than coincidental. In collecting data, particularly from app reviews, we plan to screen for anthropomorphic language used to describe or address AI systems. We also propose that several contextual factors may influence this language. These include AI usage (for example, whether AI is used for work, advice, or emotional support), AI purpose (since different systems are designed for general assistance versus specialized chatbot functions), and AI customization (such as response style, tone, or added voice features, including perceived gender). Each of these elements may shape how users conceptualize and describe AI. By integrating these dimensions, we aim to better understand whether there is a relationship between how people perceive AI and the extent to which they talk about it in human-like versus machine-like terms(he/she/them vs it).\n",
    "\n",
    "**References**\n",
    "1. https://www.pewresearch.org/science/2025/09/17/how-americans-view-ai-and-its-impact-on-people-and-society/  \n",
    "2. https://techequity.us/2025/10/07/how-people-really-feel-about-ai-from-sea-to-shining-se/   \n",
    "3. https://www.pewresearch.org/wp-content/uploads/sites/20/2025/12/PI_2025.12.09_Teens-Social-Media-AI_REPORT.pdf  \n",
    "4. https://imaginingthedigitalfuture.org/reports-and-publications/close-encounters-of-the-ai-kind/\n",
    "5. https://link.springer.com/article/10.1007/s11747-020-00762-y#Sec12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis (H₀): There is no significant association between the degree of anthropomorphic language used in app store reviews of AI systems and the star ratings given by users. In other words, whether a reviewer frames an AI system as a human-like entity or as a purely functional tool does not predict their reported level of satisfaction.\n",
    "\n",
    "Alternative Hypothesis (H₁): There is a significant positive association between the degree of anthropomorphic language used in app store reviews of AI systems and the star ratings given by users. Specifically, reviews that frame AI systems using more anthropomorphic language (i.e., treating AI as another individual) will be associated with higher star ratings compared to reviews that use predominantly instrumental language (i.e., treating AI as a tool).\n",
    "\n",
    "We predict a significant positive association between anthropomorphic language and higher star ratings for three converging reasons drawn from the background literature. First, Blut et al. (2021) (Source 6) synthesized 108 studies involving over 11,000 individuals and found that customer anthropomorphism of AI systems, including chatbots, functions as a positive mediator toward user intention and satisfaction, operating through increased perceptions of social presence and trust. This suggests that users who psychologically engage with AI as a social partner rather than a mechanical instrument are likely to report more favorable experiences. Second, Cheng et al. (2025) (Source 7) demonstrated using over 12,000 nationally representative responses that perceptions of AI's human-likeness significantly predict both trust and willingness to adopt AI (r² = 0.21, p < 0.001), and that these anthropomorphic perceptions increased by 34% over a single year, indicating that the trend toward viewing AI as more human-like is becoming more and more prevalent. Third, Epley, Waytz, and Cacioppo (2007) (Source 8) established that anthropomorphism is driven in part by sociality motivation: a deep human need to connect socially, which implies that users who express anthropomorphic language about an AI app are likely doing so because the interaction fulfilled a social need, an experience that would naturally translate into greater satisfaction and, consequently, higher star ratings. Furthermore, we will explore the relationships between multiple dimensions (AI usage, AI purpose, and AI customization) and people’s attitude towards AI as well as their satisfaction level.\n",
    "\n",
    "Although the weight of evidence supports our directional prediction, it is important to acknowledge that the relationship between anthropomorphic language and satisfaction may not be significant. Crolic et al. (2022) (Source 9) found across five studies, including a large real-world telecommunications dataset, that chatbot anthropomorphism actually produced a negative effect on customer satisfaction when users entered the interaction in an angry emotional state, because anthropomorphic framing inflated expectations of the chatbot's capabilities and set the stage for expectancy violations when those expectations went unmet, a dynamic that could similarly contaminate app store reviews, where frustrated users are disproportionately likely to write reviews in the first place. Furthermore, Blut et al. (2021) (Source 6) noted in their meta-analysis that the positive effects of anthropomorphism on satisfaction were heavily moderated by context and task type, meaning that in utilitarian, task-completion-oriented interactions, arguably the dominant use case for most AI apps, instrumental framing may matter as much or more than anthropomorphic framing for predicting user satisfaction.\n",
    "\n",
    "**References**\n",
    "6. Blut, M., Wang, C., Wünderlich, N. V., & Brock, C. (2021). Understanding anthropomorphism in service provision: A meta-analysis of physical robots, chatbots, and other AI. Journal of the Academy of Marketing Science, 49(4), 632–658. https://doi.org/10.1007/s11747-020-00762-y  \n",
    "7. Cheng, M., Lee, A. Y., Rapuano, K., Niederhoffer, K., Liebscher, A., & Hancock, J. T. (2025). From tools to thieves: Measuring and understanding public perceptions of AI through crowdsourced metaphors. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT '25). https://arxiv.org/abs/2501.18045   \n",
    "8. Epley, N., Waytz, A., & Cacioppo, J. T. (2007). On seeing human: A three-factor theory of anthropomorphism. Psychological Review, 114(4), 864–886. https://doi.org/10.1037/0033-295X.114.4.864  \n",
    "9. Crolic, C., Thomaz, F., Hadi, R., & Stephen, A. T. (2022). Blame the bot: Anthropomorphism and anger in customer–chatbot interactions. Journal of Marketing, 86(1), 132–148. https://doi.org/10.1177/00222429211045687 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. The **ideal** dataset \n",
    "   1. Variables: The IV is the user's attitude towards AI (another individual vs. a tool) operationalized as the use of anthropomorphic versus instrumental language in app store reviews. The DV are the user's ratings (i.e. scores) to Gen AI models. \n",
    "   2. How many observations needed: Our study focuses relies on extracting specific reviews that mention anthropomorphic or utilitarian keywords, however many comments are non-substantive (e.g. 'Nice'). In order to ensure we retain sufficient statistical power after data cleaning and keyword filtering, we plan to scrape about 5,000 raw reviews per app (ChatGPT, Gemini, Claude), resulting in a total raw dataset of roughly 15,000 observations. This sample size provides a safety margin to account for the expected data loss dring the data wrangling. \n",
    "   3. How the data will be collected: All of the app reviews are directly scraped from the Google Play Store by our group members, referring to the scraping method published by Kaggle user Ashish Humar. The dataset includes the variables and also the review time, username, id, thumb-up count, and version. Username and id will be cleaned due to ethics, privacy, and useless, while others may be considered as weighting factor or control variables. \n",
    "   4. How the data will be stored and organized: The scraped data will be stored in CSV files and stored in our Github repository. The too short or non-substantial review content and the personality identifiable information (username and id) will be dropped. The cleaned three datasets will be merged into one, but the name of the apps will be kept for data analysis and EDA. \n",
    "2. Potential **real** datasets \n",
    "   1. Dataset 1: Google Play Store reviews of ChatGPT\n",
    "      - [Scraping Method Reference](https://www.kaggle.com/code/ashishkumarak/chatgpt-google-play-reviews-scraping/notebook)\n",
    "      - Source: self-scrape\n",
    "      - We will use the 'content' column from which we will extract words and decide the anthropomorphic level. And we will use the 'score' column as a proxy of user satisfaction to analyze the potential correlation between the anthropomorphic level and user satisfaction. \n",
    "   3. Dataset 2: Google Play Store reviews of Gemini \n",
    "      - Source: self-scrape \n",
    "      - We will use the review content and rating to see whether users like to give positive or negative scores for anthropomorphic or industrial features. This dataset is for covering more AI models. \n",
    "   4. Dataset 3: Google Play Store reviews of Claude \n",
    "      - Source: self-scrape \n",
    "      - We will use the review content and rating to see whether users like to give positive or negative scores for anthropomorphic or industrial features. This dataset is for covering more AI models. \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> Example of how to use the checkbox, and also of how you can put in a short paragraph that discusses the way this checklist item affects your project.  Remove this paragraph and the X in the checkbox before you fill this out for your project\n",
    "\n",
    " - [ ] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [ ] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [ ] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [ ] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [ ] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [ ] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work\n",
    "  \n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*: Do not show up late for meetings\n",
    "* *Team Expectation 2*: Complete your section of the work by the deadline of the week\n",
    "* *Team Expecation 3*: If you cannot make it or will be very late, give a heads up\n",
    "* *Team Expecation 4*: Be respectful to each other\n",
    "* *Team Expecation 5*: Attend the team meeting every week\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "| Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/2  |  3 PM | Determine the RQ, do background research on the topic  | Research potential tasets to use; work on research proposal | \n",
    "| 2/4  |  N/A |  Project Proposal | N/A | \n",
    "| 2/9  | 3 PM  | Import and wrangling data  | Discuss data analysis plan; address TA feedback on the project proposal   |\n",
    "| 2/16  | 3 PM  | Finalized data wrangling | Discuss and analyze the data   |\n",
    "| 2/18  | N/A  | Data Checkpoint | N/A |\n",
    "| 2/23  | 3 PM  | |  |\n",
    "| 3/2  | 3 PM  | Complete Analysis | Discuss/draft reselts, discussion, conclusion |\n",
    "| 3/4  | N/A  | EDA Checkpoint | N/A |\n",
    "| 3/9  | 3 PM  | Edit full project | Refine final project |\n",
    "| 3/18  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
